# 方法一：未自定义Patitioner

## 基本逻辑

#### Mapper

* Input
  * key：文本段落相对于全文的line offset
  * value：第offset行的文本内容
  
* Output
  * key：有效单词
  * value：文件名#词频
  
* 操作流程：
  
  * 读入停用词表：**停用词表只在Map过程用到**
  
    * 重构Mapper的setup函数，将停用词表读入；
  
      > * setup函数的作用：
      >   * MapReduce框架仅执行一次，在执行Map任务前，进行相关变量或者资源的集中初始化工作；
      >   * 若是将资源初始化工作放在方法map()中，导致Mapper任务在解析每一行输入时都会进行资源初始化工作，导致重复，程序运行效率不高；
      > * cleanup函数的作用：
      >   * MapReduce框架仅执行一次，在执行完毕Map任务后，进行相关变量或资源的释放工作；
      >   * 若是将释放资源工作放入方法map()中，也会导 致Mapper任务在解析、处理每一行文本后释放资源，而且在下一行文本解析前还要重复初始化，导致反复重复，程序运行效率不高；
  
  * 获取文件名 √
  * 根据正则表达式分割第offset行的文本，获得该行单词集 √
  * 使用Map结构，对单行重复的单词计数
  * 将Map中的内容输出，格式为：<word, fileName#wordcount>

#### Reducer

* Input

  * key：单词
  * value：文件名#词频

* Output

  * key：单词
  * value：<文件1, 词频>;<文件2, 词频>;...;<total, 总词频>;

* 操作流程：

  * 遍历Input的values，将相同文件名项目的词频数相加，整合为1个<filename, count>项目

    ==为了保证文件名有序，使用TreeMap实现这个过程，key是文件名==

  * 遍历TreeMap的项目，拼接字符串得到**<文件名, 词频>;**样式的输出

  * 最后在尾部加上<total, 总词频>;得到最终输出

## 注意事项

* 读取停用词时需要使用trim去除词头尾空格；

* 使用HashSet或TreeSet保存stopwords，便于快速查找；

* 使用TreeMap合并相同文件名的词频，保证文件名有序；

# 方法二：自定义Patitioner

## 基本逻辑

## 注意事项